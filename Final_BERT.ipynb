{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f08749b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\makri\\.conda\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\makri\\.conda\\envs\\tf\\lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\makri\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\makri\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import mixed_precision\n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "from transformers import BertTokenizer\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "os.chdir('C:/Users/makri/OneDrive/Documents/GitHub/Deep_Learning_Final_Project')\n",
    "\n",
    "data_train = pd.read_csv('all_train(1).tsv', sep='\\t')\n",
    "data_test = pd.read_csv('all_test_public.tsv', sep='\\t')\n",
    "data_validate = pd.read_csv('all_validate.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9257fc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory growth enabled for PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth for the first (and only) GPU\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(f\"Memory growth enabled for {gpus[0]}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)  # This happens if GPUs are initialized before setting memory growth\n",
    "else:\n",
    "    print(\"No GPU found. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8a7d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "SEED = 42\n",
    "# Training data\n",
    "X_train = data_train['clean_title'].values  \n",
    "y_train = data_train['2_way_label'].values \n",
    "\n",
    "# Validation data\n",
    "X_val = data_validate['clean_title'].values\n",
    "y_val = data_validate['2_way_label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b8a054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [str(x) for x in X_train]\n",
    "X_val = [str(x) for x in X_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323ce5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\makri\\.conda\\envs\\tf\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding='max_length', max_length=30, return_tensors=\"tf\")\n",
    "\n",
    "val_encodings = tokenizer(\n",
    "    X_val,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    max_length=30,\n",
    "    return_tensors=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "466a9cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "inputs = {\n",
    "    'input_word_ids': train_encodings['input_ids'],\n",
    "    'input_mask': train_encodings['attention_mask'],\n",
    "    'input_type_ids': train_encodings['token_type_ids']\n",
    "}\n",
    "labels = tf.cast(y_train, tf.float32)\n",
    "\n",
    "\n",
    "val_inputs = {\n",
    "    'input_word_ids': val_encodings['input_ids'],\n",
    "    'input_mask': val_encodings['attention_mask'],\n",
    "    'input_type_ids': val_encodings['token_type_ids']\n",
    "}\n",
    "val_labels = tf.cast(y_val, tf.float32)\n",
    "\n",
    "\n",
    "# Now build dataset properly\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((inputs,  labels)).shuffle(buffer_size=len(X_train),seed=SEED).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_inputs, val_labels))\\\n",
    "         .batch(BATCH_SIZE)\\\n",
    "         .prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bef8fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4050 Laptop GPU, compute capability 8.9\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_mask (InputLayer)        [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " input_type_ids (InputLayer)    [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " input_word_ids (InputLayer)    [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'encoder_outputs':  109482241   ['input_mask[0][0]',             \n",
      "                                 [(None, 30, 768),                'input_type_ids[0][0]',         \n",
      "                                 (None, 30, 768),                 'input_word_ids[0][0]']         \n",
      "                                 (None, 30, 768),                                                 \n",
      "                                 (None, 30, 768),                                                 \n",
      "                                 (None, 30, 768),                                                 \n",
      "                                 (None, 30, 768),                                                 \n",
      "                                 (None, 30, 768),                                                 \n",
      "                                 (None, 30, 768),                                                 \n",
      "                                 (None, 30, 768),                                                 \n",
      "                                 (None, 30, 768),                                                 \n",
      "                                 (None, 30, 768),                                                 \n",
      "                                 (None, 30, 768)],                                                \n",
      "                                 'default': (None,                                                \n",
      "                                768),                                                             \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 30, 768),                                                 \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 768)}                                                       \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['keras_layer[0][13]']           \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            769         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 109,483,009\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Model\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# BERT encoder \n",
    "bert_model = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\",\n",
    "    trainable=True\n",
    ")\n",
    "\n",
    "\n",
    "# Inputs\n",
    "input_ids = tf.keras.Input(shape=(30,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "input_mask = tf.keras.Input(shape=(30,), dtype=tf.int32, name=\"input_mask\")\n",
    "type_ids = tf.keras.Input(shape=(30,), dtype=tf.int32, name=\"input_type_ids\")\n",
    "\n",
    "bert_inputs = {\n",
    "    'input_word_ids': input_ids,\n",
    "    'input_mask': input_mask,\n",
    "    'input_type_ids': type_ids\n",
    "}\n",
    "\n",
    "bert_outputs = bert_model(bert_inputs)\n",
    "cls_token = bert_outputs['pooled_output']\n",
    "\n",
    "x = tf.keras.layers.Dropout(0.1)(cls_token)\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid', dtype='float32')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask, type_ids], outputs=x)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc1fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(), optimizer = tf.keras.optimizers.Adam(2e-5), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65139686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\makri\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"Adam/gradients/StatefulPartitionedCall:1\", shape=(None,), dtype=int32), values=Tensor(\"mul_2:0\", dtype=float32), dense_shape=Tensor(\"Adam/gradients/StatefulPartitionedCall:2\", shape=(None,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54889/54889 [==============================] - 6642s 121ms/step - loss: 0.3015 - accuracy: 0.8733 - val_loss: 0.2780 - val_accuracy: 0.8854\n",
      "Epoch 2/2\n",
      "54889/54889 [==============================] - 6673s 122ms/step - loss: 0.2345 - accuracy: 0.9063 - val_loss: 0.2797 - val_accuracy: 0.8861\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, validation_data=val_ds, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a10bbfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2889/2889 [==============================] - 122s 42ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.89      0.90      0.89     49634\n",
      "        Real       0.88      0.87      0.88     42810\n",
      "\n",
      "    accuracy                           0.89     92444\n",
      "   macro avg       0.89      0.89      0.89     92444\n",
      "weighted avg       0.89      0.89      0.89     92444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test = data_test['clean_title'].values\n",
    "y_test = data_test['2_way_label'].values\n",
    "\n",
    "\n",
    "X_test = [str(x) for x in X_test]\n",
    "\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding='max_length', max_length=30, return_tensors=\"tf\")\n",
    "\n",
    "# Prepare dataset\n",
    "inputs_test = {\n",
    "    'input_word_ids': test_encodings['input_ids'],\n",
    "    'input_mask': test_encodings['attention_mask'],\n",
    "    'input_type_ids': test_encodings['token_type_ids']\n",
    "}\n",
    "\n",
    "# Predictions\n",
    "predictions = model.predict(dict(inputs_test))\n",
    "\n",
    "threshold = 0.5\n",
    "preds = (predictions>threshold).astype(int)\n",
    "\n",
    "print(classification_report(preds,y_test, target_names = ['Fake','Real']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06286287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 364). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./my_model_bert_base\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./my_model_bert_base\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./my_model_bert_base')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
